# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WGyKpOuTVgaSi6j-ijNgpn-kbYdMSjD_
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

r = pd.read_csv('dataset_phishing.csv')
print(r)

import pandas as pd

from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import balanced_accuracy_score
from xgboost import XGBRegressor
# import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression

r.columns

from sklearn.model_selection import train_test_split


y = r.status
X = r.drop(['status'], axis=1)


X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,
                                                                random_state=0)


categorical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and 
                        X_train_full[cname].dtype == "object"]


numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]


my_cols = categorical_cols + numerical_cols
X_train = X_train_full[my_cols].copy()
X_valid = X_valid_full[my_cols].copy()

numerical_transformer = SimpleImputer(strategy='constant')


categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])


preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ])

# print(r.describe)

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y_train = le.fit_transform(y_train)

y_valid = le.fit_transform(y_valid)

# print(y_train)

import xgboost as xgb
from sklearn.metrics import accuracy_score

model = xgb.XGBClassifier()
  
my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                              ('model', model)
                             ])

  
my_pipeline.fit(X_train, y_train)

 
preds = my_pipeline.predict(X_valid)
print(accuracy_score(preds,y_valid))

import joblib

filename = 'finalized.sav'
joblib.dump(model, filename)

model = joblib.load('finalized.sav')

!pip install tldextract
import tldextract

def extract_features(url):
    features = []
    # Extract domain and subdomain from the URL
    domain, subdomain, suffix = tldextract.extract(url)
    # Add length of the domain and subdomain
    features.append(len(domain))
    features.append(len(subdomain))
    # Add number of dots in the URL
    features.append(url.count('.'))
    # Add number of hyphens in the URL
    features.append(url.count('-'))
    return features

# Use the model to predict whether a new URL is a phishing website or not
url = input("Enter any URL: ") #'https://facebook.com'
features = extract_features(url)
prediction = model.predict([features])
if prediction == 1:
    print('The website', url, 'is a phishing website.')
else:
    print('The website', url, 'is not a phishing website.')